Metadata-Version: 2.1
Name: ZiTokenizer
Version: 0.0.7
Summary: ZiTokenizer: tokenize world text as Zi
Home-page: https://github.com/laohur/ZiCutter
Author: laohur
Author-email: laohur@gmail.com
License: [Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)
Keywords: UnicodeTokenizer,ZiCutter,ZiTokenizer,Tokenizer,Unicode,laohur
Requires-Python: >=3.0
Description-Content-Type: text/markdown
Requires-Dist: logzero
Requires-Dist: pyahocorasick

# ZiTokenizer

ZiTokenizer: tokenize word as Zi

word => prefix + root + suffix

support 325 languages + global, including global 
## use
* pip install ZiTokenizer
* toeknize language frequency and count word frequency (https://github.com/laohur/UnicodeTokenizer/blob/master/test/count_lang/count_word.py)
```python
from ZiTokenizer.ZiTokenizer import ZiTokenizer

# use
tokenizer = ZiTokenizer(lang="global")  # lang='ar', 'en', 'fr', 'ru', 'zh' ...
line = "ï¡¿'ã€‡ã¡[à¸„à¸¸à¸“à¸ˆà¸°à¸ˆà¸±à¸”à¸à¸´à¸˜à¸µà¹à¸•à¹ˆà¸‡à¸‡à¸²à¸™à¹€à¸¡à¸·à¹ˆà¸­à¹„à¸£à¸„à¸°à¸±à¸µà¸´à¹Œà¸·à¹‡à¹à¸¶]â…§pays-g[ran]d-blanc-Ã©levÃ© Â» (ç™½é«˜å¤§å¤åœ‹)ç†µğŸ˜€'\x0000ç†‡"
tokens = tokenizer.tokenize(line)
print(' '.join(tokens)) # ' ã€‡ ã¡ [ à¸„ à¸“-- à¸ˆ-- à¸° --à¸ˆ à¸”-- à¸ à¸˜ à¹à¸• à¸‡-- à¸‡à¸²-- à¸™-- à¹€à¸¡ à¸­à¹„-- à¸£ --à¸„ --à¸° ] ##s ht pays - g [ ran ] d - blanc - eleve Â» ( ç™½ é«˜ å¤§ å¤ åœ‹ ) â¿° ç« å•† ##g ce ' 00 â¿° ç« é«˜

# build 
tokenizer = ZiTokenizer(mydir) # mydir include "word_frequency.tsv"
tokenizer.build(min_ratio=1.5e-6, min_freq=3)
tokenizer = ZiTokenizer(dir=mydir)

```
